{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 06 - Experiment Notebook",
        "",
        "Use this notebook to quickly test different approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd",
        "import numpy as np",
        "import xgboost as xgb",
        "from sklearn.model_selection import cross_val_score, TimeSeriesSplit",
        "from pathlib import Path",
        "import warnings",
        "warnings.filterwarnings('ignore')",
        "",
        "BASE_PATH = Path('..')",
        "FEATURES_PATH = BASE_PATH / 'features_v2'",
        "",
        "# Load data",
        "df = pd.read_csv(FEATURES_PATH / 'forecast_sku_weekly_H1.csv')",
        "print(f\"Loaded: {len(df):,} rows\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment: Different Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick feature prep",
        "df['sku_encoded'] = pd.factorize(df['sku'])[0]",
        "",
        "feature_cols = ['sku_encoded', 'week_num']",
        "if 'lag1_quantity' in df.columns:",
        "    feature_cols.extend(['lag1_quantity', 'lag2_quantity'])",
        "",
        "df_clean = df.dropna(subset=feature_cols)",
        "X = df_clean[feature_cols]",
        "y = df_clean['weekly_revenue']",
        "",
        "print(f\"Training data: {len(X):,} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test different configurations",
        "configs = [",
        "    {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.1},",
        "    {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1},",
        "    {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.05},",
        "]",
        "",
        "results = []",
        "for cfg in configs:",
        "    model = xgb.XGBRegressor(**cfg, random_state=42, n_jobs=-1)",
        "    ",
        "    # Time series cross-validation",
        "    tscv = TimeSeriesSplit(n_splits=3)",
        "    scores = cross_val_score(model, X, y, cv=tscv, scoring='neg_mean_absolute_error')",
        "    ",
        "    results.append({",
        "        **cfg,",
        "        'cv_mae': -scores.mean(),",
        "        'cv_std': scores.std()",
        "    })",
        "    print(f\"{cfg} -> MAE: {-scores.mean():,.0f} (+/- {scores.std():,.0f})\")",
        "",
        "results_df = pd.DataFrame(results)",
        "print(\"\\nBest config:\")",
        "print(results_df.loc[results_df['cv_mae'].idxmin()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes",
        "",
        "Add your experiment observations here:",
        "",
        "- ...",
        "- ..."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}